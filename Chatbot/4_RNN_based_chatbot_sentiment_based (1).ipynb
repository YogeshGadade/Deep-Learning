{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 RNN_based_chatbot_sentiment_based.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_iQB-WQ8Sk0"
      },
      "source": [
        "# Chat bot development ( Based on Sentiment using RNN )\n",
        "\n",
        "## Developer: Yogesh Awdhut Gadade\n",
        "\n",
        "#### Input dataset: Topical chat (Amazon Alexa AI) \n",
        "\n",
        "#### system configuration: \n",
        "- Program run on 16 GB RAM, 6 GB of GPU\n",
        "\n",
        "#### Which package needs to be installed\n",
        "- tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMiXzO0l8Sk5"
      },
      "source": [
        "from pandas import DataFrame, read_json, read_csv\n",
        "import gc          # Garbage collector\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVJScR5D8Sk6"
      },
      "source": [
        "#### Versions of python and packages used in this notebook:\n",
        "1. Python: 3\n",
        "2. Pandas: 1.0.5 (!pip show pandas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UD_2Guf9O5D",
        "outputId": "dedaab0c-40d7-4760-f44d-c9929d2f7551"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVqbOrun8Sk7"
      },
      "source": [
        "strInputDirPath=\".//input//train.json\" # Set current input directory path\n",
        "\n",
        "strInputDirPath=\"/content/drive/MyDrive/Stevens/Deep Learning/input/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5iGcu-a8Sk_"
      },
      "source": [
        "# On local machine:\n",
        "#pdChatData=read_csv(\"ChatExpanded.csv\")\n",
        "# on google drive\n",
        "pdChatData=read_csv(strInputDirPath+\"sampling.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiXsbeLX8SlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4af28ef-0d27-4815-df15-3a6663db24d0"
      },
      "source": [
        "pdChatData.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['conversation_id', 'config', 'agent', 'message', 'agent_1Overall',\n",
              "       'agent_2Overall', 'sentiment', 'turn_rating', 'knowledge_source',\n",
              "       'article_url', 'LemmatizedText'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xuUFKYP8SlA",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "d911b99a-80b9-4ca0-ef2c-dee65d9b21ee"
      },
      "source": [
        "pdChatData.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>config</th>\n",
              "      <th>agent</th>\n",
              "      <th>message</th>\n",
              "      <th>agent_1Overall</th>\n",
              "      <th>agent_2Overall</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>turn_rating</th>\n",
              "      <th>knowledge_source</th>\n",
              "      <th>article_url</th>\n",
              "      <th>LemmatizedText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>t_86627de2-fe27-42f1-9250-85054ba5353b</td>\n",
              "      <td>B</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Have you seen Ethiopias version of Top Chef?</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "      <td>Good</td>\n",
              "      <td>FS2</td>\n",
              "      <td>https://www.washingtonpost.com/news/inspired-l...</td>\n",
              "      <td>see ethiopia version top chef</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>t_f3a6d5fb-7f18-41e9-9ab1-5599d265812f</td>\n",
              "      <td>C</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>It has been a pleasure talking to you too.  En...</td>\n",
              "      <td>Good</td>\n",
              "      <td>Passable</td>\n",
              "      <td>Happy</td>\n",
              "      <td>Good</td>\n",
              "      <td>Personal Knowledge</td>\n",
              "      <td>https://www.washingtonpost.com/local/human-rem...</td>\n",
              "      <td>pleasur talk enjoy rap music internet</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          conversation_id  ...                         LemmatizedText\n",
              "0  t_86627de2-fe27-42f1-9250-85054ba5353b  ...          see ethiopia version top chef\n",
              "1  t_f3a6d5fb-7f18-41e9-9ab1-5599d265812f  ...  pleasur talk enjoy rap music internet\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktqhOUtX8SlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0aa29e6-3097-4751-ee55-086dd9e5ae63"
      },
      "source": [
        "print(f\"Total number of chats (conversations) : {len(pdChatData)}\")\n",
        "print(f\"Total number of Agents                : {len(pdChatData.agent.unique()), list(pdChatData.agent.unique())}\")\n",
        "print(f\"Total number of sentiment             : {len(pdChatData.sentiment.unique()), list(pdChatData.sentiment.unique())}\")\n",
        "print(f\"Total number of knowledge_source      : {len(pdChatData.knowledge_source.unique()), list(pdChatData.knowledge_source.unique())}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of chats (conversations) : 25633\n",
            "Total number of Agents                : (2, ['agent_1', 'agent_2'])\n",
            "Total number of sentiment             : (8, ['Curious to dive deeper', 'Happy', 'Surprised', 'Neutral', 'Sad', 'Fearful', 'Disgusted', 'Angry'])\n",
            "Total number of knowledge_source      : (8, ['FS2', 'Personal Knowledge', 'FS3', 'FS1', 'AS3', 'AS1', 'AS4', 'AS2'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kVCc8AR8SlE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "301befbf-6a98-483a-98a5-9b2054fed954"
      },
      "source": [
        "pdChatData.groupby('sentiment').count().sort_values('conversation_id')['conversation_id'].plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f327829a910>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCH-tEjq8SlE"
      },
      "source": [
        "### OBSERVATION:\n",
        "- In the subsample we got from the above step giving us the same distribution as the original dataset has. Hence going to use this for further training and tesing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6VXc4O4if_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b4b3b0-0852-4730-8dde-926de6e0be5e"
      },
      "source": [
        "# if not present download following\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZDfebFf8SlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06958654-fc57-44c5-a508-98af86eda5d0"
      },
      "source": [
        "print('Total number of rows we have: ', len(pdChatData))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows we have:  25633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mErLbU3n8SlG"
      },
      "source": [
        "#5. encoding the outputs: target variables are also encoded to decimal values. \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "pdChatData['Labels']=le.fit_transform(pdChatData.sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EndXBI8F8SlO"
      },
      "source": [
        "# Chatbot based on sentiment using RNN(LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lmXIIl48SlO",
        "scrolled": true
      },
      "source": [
        "import string\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "tokenizer=''\n",
        "def preprocess_data_for_rnn(data):\n",
        "    global tokenizer\n",
        "    #1. Removing punctuations\n",
        "    #data['inputs'] = data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "    #data['inputs'] = data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
        "\n",
        "    #2. Tokenize the data\n",
        "    tokenizer = Tokenizer(num_words=10000)\n",
        "    tokenizer.fit_on_texts(data['inputs'])\n",
        "    #Tensorflow’s tokenizer assigns a unique token to each distinct word. \n",
        "\n",
        "\n",
        "    #3. Transform/Convert text to sequence\n",
        "    train = tokenizer.texts_to_sequences(data['inputs'])\n",
        "\n",
        "    #4. Apply padding: padding is done to get all the data to the same length so as to send it to an RNN layer. \n",
        "    x_train = pad_sequences(train)\n",
        "\n",
        "    #5. encoding the outputs: target variables are also encoded to decimal values. \n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(data['tags'])\n",
        "    \n",
        "    vocabulary, input_shape, output_length=get_model_input_values(x_train, tokenizer, le)\n",
        "    \n",
        "    return x_train, y_train, vocabulary, input_shape, output_length\n",
        "\n",
        "def get_model_input_values(x_train, tokenizer, le):\n",
        "    #input length\n",
        "    input_shape = x_train.shape[1]\n",
        "    print(\"Input shape: \", input_shape)\n",
        "    #define vocabulary\n",
        "    vocabulary = len(tokenizer.word_index)\n",
        "    print(\"number of unique words in vocabulary: \",vocabulary)\n",
        "    #output length\n",
        "    output_length = le.classes_.shape[0]\n",
        "    print(\"output length: \",output_length)\n",
        "    \n",
        "    return vocabulary, input_shape, output_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOmX14ll8SlO"
      },
      "source": [
        "# Define Model: creating the model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM , Dense,GlobalMaxPooling1D,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def get_rnn_model(input_shape, vocabulary):\n",
        "\n",
        "    i = Input(shape=(input_shape,))\n",
        "    x = Embedding(vocabulary+1,333)(i)\n",
        "    x = LSTM(333,return_sequences=True)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(output_length,activation=\"softmax\")(x)\n",
        "    model  = Model(i,x)\n",
        "    #compiling the model\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8US0mns8SlO",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01e748b-dcec-4965-b268-233e2e63e574"
      },
      "source": [
        "#data=pdChatData.copy()\n",
        "data=pdChatData[['LemmatizedText', 'Labels']].astype(str).rename(columns={'LemmatizedText': 'inputs', 'Labels': 'tags'})\n",
        "data.head()\n",
        "print(\"Total Samples to train:\", len(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Samples to train: 25633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9YbXdt77usr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "b8d47400-18e6-493a-b16b-5d6de446e97d"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>see ethiopia version top chef</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pleasur talk enjoy rap music internet</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  inputs tags\n",
              "0          see ethiopia version top chef    1\n",
              "1  pleasur talk enjoy rap music internet    4"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIbAJiAd8SlO",
        "outputId": "0806075e-4402-4390-931e-34534d8603cd"
      },
      "source": [
        "#del(model)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgWBzhpI8SlP",
        "scrolled": true,
        "outputId": "9032c26e-934f-4d4d-aec2-32db24aba53e"
      },
      "source": [
        "%time x_train, y_train, vocabulary, input_shape, output_length=preprocess_data_for_rnn(data)\n",
        "model=get_rnn_model(input_shape, vocabulary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape:  53\n",
            "number of unique words in vocabulary:  10459\n",
            "output length:  8\n",
            "CPU times: user 898 ms, sys: 22.6 ms, total: 920 ms\n",
            "Wall time: 912 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5FyQ36g8SlP",
        "outputId": "86f74b51-a8bf-4913-f4fd-e1e403a92f2f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 53)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 53, 333)           3483180   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 53, 333)           888444    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 17649)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 141200    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,512,824\n",
            "Trainable params: 4,512,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXAYJGcg8SlP",
        "scrolled": true,
        "outputId": "42fe4370-35d4-4f98-84d8-cd461ab84825"
      },
      "source": [
        "#training the model\n",
        "%time modelRNN = model.fit(x_train,y_train,epochs=20, batch_size=32)  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "802/802 [==============================] - 351s 437ms/step - loss: 1.3575 - accuracy: 0.4464\n",
            "Epoch 2/20\n",
            "802/802 [==============================] - 349s 435ms/step - loss: 1.1745 - accuracy: 0.5337\n",
            "Epoch 3/20\n",
            "802/802 [==============================] - 347s 432ms/step - loss: 0.9322 - accuracy: 0.6394\n",
            "Epoch 4/20\n",
            "802/802 [==============================] - 344s 430ms/step - loss: 0.6824 - accuracy: 0.7406\n",
            "Epoch 5/20\n",
            "802/802 [==============================] - 335s 418ms/step - loss: 0.5124 - accuracy: 0.8037\n",
            "Epoch 6/20\n",
            "802/802 [==============================] - 340s 424ms/step - loss: 0.4004 - accuracy: 0.8488\n",
            "Epoch 7/20\n",
            "802/802 [==============================] - 344s 429ms/step - loss: 0.3142 - accuracy: 0.8817\n",
            "Epoch 8/20\n",
            "802/802 [==============================] - 356s 444ms/step - loss: 0.2537 - accuracy: 0.9072\n",
            "Epoch 9/20\n",
            "802/802 [==============================] - 358s 446ms/step - loss: 0.2096 - accuracy: 0.9231\n",
            "Epoch 10/20\n",
            "802/802 [==============================] - 358s 446ms/step - loss: 0.1651 - accuracy: 0.9407\n",
            "Epoch 11/20\n",
            "802/802 [==============================] - 366s 456ms/step - loss: 0.1417 - accuracy: 0.9481\n",
            "Epoch 12/20\n",
            "802/802 [==============================] - 358s 446ms/step - loss: 0.1188 - accuracy: 0.9565\n",
            "Epoch 13/20\n",
            "802/802 [==============================] - 357s 446ms/step - loss: 0.1020 - accuracy: 0.9638\n",
            "Epoch 14/20\n",
            "802/802 [==============================] - 355s 443ms/step - loss: 0.0837 - accuracy: 0.9697\n",
            "Epoch 15/20\n",
            "802/802 [==============================] - 359s 448ms/step - loss: 0.0720 - accuracy: 0.9745\n",
            "Epoch 16/20\n",
            "802/802 [==============================] - 360s 449ms/step - loss: 0.0645 - accuracy: 0.9775\n",
            "Epoch 17/20\n",
            "802/802 [==============================] - 360s 449ms/step - loss: 0.0593 - accuracy: 0.9796\n",
            "Epoch 18/20\n",
            "802/802 [==============================] - 359s 447ms/step - loss: 0.0605 - accuracy: 0.9792\n",
            "Epoch 19/20\n",
            "802/802 [==============================] - 365s 455ms/step - loss: 0.0496 - accuracy: 0.9824\n",
            "Epoch 20/20\n",
            "802/802 [==============================] - 359s 447ms/step - loss: 0.0416 - accuracy: 0.9852\n",
            "CPU times: user 3h 29min 49s, sys: 8min 21s, total: 3h 38min 11s\n",
            "Wall time: 1h 58min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw_cdAfS8SlP"
      },
      "source": [
        "# save model\n",
        "#modelRNN.('rnn_model_for_chat.h5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw6yMyhS8SlP"
      },
      "source": [
        "# save model immediately here in another notebook try to develop chat response mechanism based on sentiment prediction"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha_5C27c8SlP"
      },
      "source": [
        "The Network consist of an embedding layer which is one of the most powerful things in the field of natural language processing. the outputs of the embedding layer is the input of the reccurent layer with lstm gate. then, the output is flattened and a regular dense layer is used with a softmax activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAnS2wzB8SlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31779bcd-03ec-4617-df84-0b740672e890"
      },
      "source": [
        "pdChatData.sentiment.unique()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Curious to dive deeper', 'Happy', 'Surprised', 'Neutral', 'Sad',\n",
              "       'Fearful', 'Disgusted', 'Angry'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKZij4s98SlQ"
      },
      "source": [
        "# Response from chatbot - here use beam search technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plAL8n8d8SlQ"
      },
      "source": [
        "1. Input: These are exactly the messages that the user is going to be sending to the bot.\n",
        "2. tags : tags are used to categorise the inputs and map them to a particular type of response\n",
        "3. responses : once, we have mapped an input to an appropriate tag, we can select one of the response to give back to the user.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJDDCkKX8SlQ"
      },
      "source": [
        "# Creating responses dictionary. \n",
        "# Trained model will predict the sentiment. Responses will have chat listed for each sentiment one of which will be output\n",
        "lstSentiments=list(pdChatData.sentiment.unique())\n",
        "responses = {}\n",
        "for strSentiment in lstSentiments:\n",
        "    responses[strSentiment] = list(pdChatData[pdChatData.sentiment == strSentiment]['message'].unique())\n",
        "    \n",
        "    \n",
        "#chatting\n",
        "import random\n",
        "import numpy as np\n",
        "blFlag=True\n",
        "while blFlag:\n",
        "    texts_p = []\n",
        "    prediction_input = input('You : ')\n",
        "    if str(prediction_input) == \"exit\":\n",
        "        blFlag=False\n",
        "        break\n",
        "    #removing punctuation and converting to lowercase\n",
        "    prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "    prediction_input = ''.join(prediction_input)\n",
        "    texts_p.append(prediction_input)\n",
        "    #tokenizing and padding\n",
        "    prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "    prediction_input = np.array(prediction_input).reshape(-1)\n",
        "    prediction_input = pad_sequences([prediction_input],input_shape)\n",
        "    #getting output from model\n",
        "    output = model.predict(prediction_input)\n",
        "    output = output.argmax()\n",
        "    #finding the right tag and predicting\n",
        "    response_tag = le.inverse_transform([output])[0]\n",
        "    print(response_tag)\n",
        "    \n",
        "    \n",
        "    print(\"Chatbot : \", random.choice(responses[response_tag]))\n",
        "    \n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEAcSF-l8SlQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3SJ2JGd3O7r"
      },
      "source": [
        "## Conclusion:\n",
        "- Althoug model achieved more than 98% but the response technique will need further improvements in creating responses ( beam search )"
      ]
    }
  ]
}